{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "- Pseudo Residual for log loss"
      ],
      "metadata": {
        "id": "HJhSvwU5jJvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pseudo Residual for log loss"
      ],
      "metadata": {
        "id": "i1Q47wv5GVJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show that the negative of the derivative of the loss function (log-loss) is psuedo residual [$-(\\frac{d(L^{log})}{d(F_k(x_i))})$] which is similar to the residual (difference between actual and predicted values)"
      ],
      "metadata": {
        "id": "1T-CT6D2O639"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us assume our loss function be Log-loss and our problem is a binary classification problem\n",
        "* The output of the $k_{th}$ model $F_k(x_i) = p_i = p((y_i=1)|x_i)$ that is probability of $y_i$ being 1, given $x_i$\n",
        " * where $y_i$ is the actual class label\n",
        "\n",
        "\n",
        "We know the **loss function is log loss**\n",
        "   * $L = logloss(y_i,p_i) = y_i log p_i + (1-y_i) log(1-p_i)$"
      ],
      "metadata": {
        "id": "3gBzOm6QG4rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore,\n",
        "* $-(\\frac{\\partial L(y_i,p_i)}{\\partial(p_i)})  = -\\frac{∂([y_i log p_i + (1-y_i) log(1-p_i))}{∂p_i}$\n",
        "\n",
        "Using  product rule,\n",
        "\n",
        "$\\frac{\\partial L(y_i,p_i)}{\\partial(p_i)} = y_i.\\frac{∂(logp_i)}{∂p_i} + logp_i.\\frac{∂(y_i)}{∂p_i} + (1 - y_i)\\frac{∂(log(1 - p_i))}{∂p_i} + log(1-p_i). \\frac{∂(1-y_i)}{∂p_i} $\n",
        "\n",
        "$y_i$ is constant when we take derivative w.r.t $p_i$\n",
        "\n",
        "<br>\n",
        "\n",
        "The derivative comes out to be\n",
        "\n",
        "$- \\frac{\\partial L(y_i,p_i)}{\\partial(p_i)} = -[\\frac{y_i}{p_i} - \\frac{1-y_i}{1-p_i}] = \\frac{p_i(i-y_i) - y_1(1-p_i)}{p_i(1-p_i)}$\n",
        "\n",
        "<br>\n",
        "\n",
        "so,\n",
        " $-(\\frac{dL}{d(p_i)}) = \\frac{p_i-y_i}{p_i(1-p_i)}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L8aoIc_KIvfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here the numerator is capturing the difference which is the $(ŷ_i - y_i)$ which is key a\n",
        "- Consider denomination $p_i(1 - p_i)$ as a normalizing factor\n",
        "* Hence proved that the when we use log-loss the psuedo residual behaves like a residual."
      ],
      "metadata": {
        "id": "YE80GgSbMUzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1bAYJVOqSa1--1Rz_CVMz_zb6ClgjIliM' >"
      ],
      "metadata": {
        "id": "w5jRNH5bLf5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1ALV7CtjErWfnDu4sbUooNia8LmePfl3_' >\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EoH8g13TL81U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1bts48GdHMFIifaG3EVIvMNGEVioFuTwW' >\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pt75eiLfMFTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src='https://drive.google.com/uc?id=1Izv_aS0UzG1FcNK_yDXoTBXfp_3xnyAP' >"
      ],
      "metadata": {
        "id": "PMz2xilEMNXe"
      }
    }
  ]
}